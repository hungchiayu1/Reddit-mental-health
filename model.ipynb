{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e695dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb91fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('train.json')\n",
    "test_df = pd.read_json('test.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e22ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e175e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe982a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = torch.load('all_train_embedding.pt')\n",
    "test_embedding = torch.load('all_test_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56786555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "\n",
    "def pad_tensor_sequence(sequence, max_length, embedding_dim, padding_value=0):\n",
    "    if sequence.size(0)>max_length:\n",
    "        sequence = sequence[:max_length,:] ## Take the first max _length vector\n",
    "    padding = torch.full((max_length - sequence.size(0), embedding_dim), padding_value)\n",
    "    \n",
    "    \n",
    "    padded_sequence = torch.cat((sequence, padding), dim=0)\n",
    "    \n",
    "    attn_mask = torch.tensor(sequence.size(0)*[0]+padding.size(0)*[1],dtype=torch.float)\n",
    "    \n",
    "    return padded_sequence,attn_mask\n",
    "\n",
    "\n",
    "def data_collator_with_padding(batch, embedding_dim, padding_value=0,max_length=128):\n",
    "   \n",
    "    batch_data_attn_mask = [pad_tensor_sequence(item[0], max_length, embedding_dim, padding_value) for item in batch]\n",
    "    batch_labels = [torch.nn.functional.one_hot(torch.tensor(item[1],dtype=torch.long),7) for item in batch]\n",
    "   \n",
    "    batch_data = [item[0] for item in batch_data_attn_mask]\n",
    "    batch_attention_mask = torch.stack([item[1] for item in batch_data_attn_mask])\n",
    "    \n",
    "    batch_data_tensor = torch.stack(batch_data)\n",
    "    #print(batch_labels)\n",
    "    batch_labels_tensor = torch.stack(batch_labels)\n",
    "    \n",
    "    #batch_labels_tensor = torch.tensor(batch_labels)\n",
    "\n",
    "    return batch_data_tensor, batch_labels_tensor.float(), batch_attention_mask\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "\n",
    "#data = [v for v in neg_post_embedding_dict.values()]\n",
    "#data.extend([p for p in adhd_post_embedding_dict.values()])\n",
    "#labels = [0]*len(neg_post_embedding_dict)\n",
    "#labels.extend([1]*len(adhd_post_embedding_dict))\n",
    "\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=16, collate_fn=lambda batch: data_collator_with_padding(batch, 768))\n",
    "\n",
    "#for batch_data, batch_labels,batch_attention_mask in a:\n",
    "    \n",
    "    #pass#print(\"Batch data shape:\", batch_data.shape)\n",
    "   # print(\"Batch labels:\", batch_labels)\n",
    "\n",
    "def create_dataloader_from_post_embedding(post_embedding,df,batch_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for author,frame in df.groupby('author'):\n",
    "        data.append(post_embedding[frame.index])\n",
    "        labels.append(frame['label'].iloc[0])\n",
    "        \n",
    "    dataset = CustomDataset(data,labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=lambda batch: data_collator_with_padding(batch, 768))\n",
    "    \n",
    "    return dataloader\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "def1a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader_from_post_embedding(train_embedding,train_df,32)\n",
    "test_dataloader = create_dataloader_from_post_embedding(test_embedding,test_df,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68bdcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "class UserEmbedder(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_layer=4):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.MultiheadAttention(768, 6,batch_first=True) for _ in range(n_layer)])\n",
    "        #self.self_attention = nn.MultiheadAttention(768,4,batch_first=True)\n",
    "        self.layer_norm = nn.ModuleList([nn.LayerNorm(768) for _ in range(n_layer)])\n",
    "        self.mean_pooling = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "    def forward(self,x,key_padding_mask=None):\n",
    "        residual = x\n",
    "        for multihead_attention,layer_norm in zip(self.layers,self.layer_norm):\n",
    "           \n",
    "            x,_ = multihead_attention(x,x,x,key_padding_mask=key_padding_mask)\n",
    "            x = residual+x\n",
    "            x = layer_norm(x)\n",
    "            residual = x\n",
    "            \n",
    "        \n",
    "        x = torch.mean(x,axis=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_layer=4):\n",
    "        super().__init__()\n",
    "        self.userembedder = UserEmbedder(n_layer)\n",
    "        self.fc = nn.Linear(768,64)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(64,7)\n",
    "        \n",
    "    def forward(self,x,src_mask=None):\n",
    "        x = self.userembedder(x,key_padding_mask=src_mask)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f5ac806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,val_dataloader,device):\n",
    "    \n",
    "    print(\"----- Evaluating ------\")\n",
    "    \n",
    "    model.eval()\n",
    "   \n",
    "    all_predictions = torch.tensor([])\n",
    "    all_labels = torch.tensor([])\n",
    "   \n",
    "    model = model.to(device)\n",
    "    \n",
    "    with torch.no_grad(): ## Disable gradient\n",
    "         for inputs, labels,attn_mask in tqdm(val_dataloader):\n",
    "\n",
    "            #inputs,labels = batch\n",
    "            #print(inputs,attn_mask)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            attn_mask = attn_mask.to(device)\n",
    "            \n",
    "            logits = model(inputs,attn_mask)\n",
    "            \n",
    "            \n",
    "            \n",
    "            max_index = torch.argmax(logits,axis=-1).cpu()\n",
    "            pred = torch.nn.functional.one_hot(max_index,7)\n",
    "            \n",
    "            labels = labels.cpu()\n",
    "            all_predictions = torch.cat((all_predictions,pred),axis=0)\n",
    "            all_labels = torch.cat((all_labels,labels),axis=0)\n",
    "\n",
    "    class_indices = torch.argmax(all_labels,axis=1)\n",
    "    prediction_indices = torch.argmax(all_predictions,axis=1)\n",
    "    f1 = f1_score(all_predictions,all_labels,average=None)\n",
    "    acc = torch.sum(class_indices==prediction_indices)/len(prediction_indices)\n",
    "    print(f1)\n",
    "    print(\"ACC\",acc)\n",
    "    return {\"pred\":all_predictions,\"labels\":all_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c343bb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                | 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███████████▏                                                                                                                                                            | 4/60 [00:00<00:01, 35.26it/s]\u001b[A\n",
      " 13%|██████████████████████▍                                                                                                                                                 | 8/60 [00:00<00:01, 36.53it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▍                                                                                                                                     | 12/60 [00:00<00:01, 37.05it/s]\u001b[A\n",
      " 27%|████████████████████████████████████████████▌                                                                                                                          | 16/60 [00:00<00:01, 37.34it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                               | 20/60 [00:00<00:01, 37.45it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 24/60 [00:00<00:00, 37.46it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████████████████████████████████████████████▉                                                                                         | 28/60 [00:00<00:00, 37.50it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████                                                                              | 32/60 [00:00<00:00, 37.57it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 36/60 [00:00<00:00, 37.51it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 40/60 [00:01<00:00, 37.59it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 44/60 [00:01<00:00, 37.61it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 48/60 [00:01<00:00, 37.55it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 52/60 [00:01<00:00, 37.54it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.69it/s]\u001b[A\n",
      "  4%|██████▋                                                                                                                                                                 | 1/25 [00:20<08:20, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18546366 0.00664452 0.34608985 0.34709193 0.64135021 0.19649123\n",
      " 0.65789474]\n",
      "ACC tensor(0.3843)\n",
      "----- Evaluating ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                | 0/60 [00:00<?, ?it/s]\u001b[A/home/cyhung/home/miniconda3/envs/generation_classification/lib/python3.7/site-packages/torch/nn/modules/activation.py:1138: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:126.)\n",
      "  1 if key_padding_mask is not None else 0 if attn_mask is not None else None)\n",
      "\n",
      "  7%|███████████▏                                                                                                                                                            | 4/60 [00:00<00:01, 34.29it/s]\u001b[A\n",
      " 13%|██████████████████████▍                                                                                                                                                 | 8/60 [00:00<00:01, 34.73it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▍                                                                                                                                     | 12/60 [00:00<00:01, 35.28it/s]\u001b[A\n",
      " 27%|████████████████████████████████████████████▌                                                                                                                          | 16/60 [00:00<00:01, 35.77it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                               | 20/60 [00:00<00:01, 35.94it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 24/60 [00:00<00:00, 36.08it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████████████████████████████████████████████▉                                                                                         | 28/60 [00:00<00:00, 36.21it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████                                                                              | 32/60 [00:00<00:00, 36.26it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 36/60 [00:01<00:00, 36.30it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 40/60 [00:01<00:00, 36.36it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 44/60 [00:01<00:00, 36.41it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 48/60 [00:01<00:00, 36.41it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 52/60 [00:01<00:00, 36.46it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.35it/s]\u001b[A\n",
      "  8%|█████████████▍                                                                                                                                                          | 2/25 [00:41<08:01, 20.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.245      0.16066482 0.41476274 0.35860656 0.68224299 0.08333333\n",
      " 0.77674419]\n",
      "ACC tensor(0.4514)\n",
      "----- Evaluating ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                | 0/60 [00:00<?, ?it/s]\u001b[A/home/cyhung/home/miniconda3/envs/generation_classification/lib/python3.7/site-packages/torch/nn/modules/activation.py:1138: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:126.)\n",
      "  1 if key_padding_mask is not None else 0 if attn_mask is not None else None)\n",
      "\n",
      "  7%|███████████▏                                                                                                                                                            | 4/60 [00:00<00:01, 33.80it/s]\u001b[A\n",
      " 13%|██████████████████████▍                                                                                                                                                 | 8/60 [00:00<00:01, 34.97it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▍                                                                                                                                     | 12/60 [00:00<00:01, 35.53it/s]\u001b[A\n",
      " 27%|████████████████████████████████████████████▌                                                                                                                          | 16/60 [00:00<00:01, 35.75it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                               | 20/60 [00:00<00:01, 35.77it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 24/60 [00:00<00:01, 35.85it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████████████████████████████████████████████▉                                                                                         | 28/60 [00:00<00:00, 35.93it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████                                                                              | 32/60 [00:00<00:00, 36.01it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 36/60 [00:01<00:00, 36.01it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 40/60 [00:01<00:00, 36.04it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 44/60 [00:01<00:00, 36.03it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 48/60 [00:01<00:00, 36.04it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 52/60 [00:01<00:00, 36.03it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.17it/s]\u001b[A\n",
      " 12%|████████████████████▏                                                                                                                                                   | 3/25 [01:02<07:41, 20.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25587467 0.21852732 0.40787623 0.38145695 0.73315364 0.36871508\n",
      " 0.75462392]\n",
      "ACC tensor(0.4682)\n",
      "----- Evaluating ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                | 0/60 [00:00<?, ?it/s]\u001b[A/home/cyhung/home/miniconda3/envs/generation_classification/lib/python3.7/site-packages/torch/nn/modules/activation.py:1138: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:126.)\n",
      "  1 if key_padding_mask is not None else 0 if attn_mask is not None else None)\n",
      "\n",
      "  7%|███████████▏                                                                                                                                                            | 4/60 [00:00<00:01, 34.44it/s]\u001b[A\n",
      " 13%|██████████████████████▍                                                                                                                                                 | 8/60 [00:00<00:01, 35.84it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▍                                                                                                                                     | 12/60 [00:00<00:01, 36.30it/s]\u001b[A\n",
      " 27%|████████████████████████████████████████████▌                                                                                                                          | 16/60 [00:00<00:01, 36.62it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                               | 20/60 [00:00<00:01, 36.72it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 24/60 [00:00<00:00, 36.79it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████████████████████████████████████████████▉                                                                                         | 28/60 [00:00<00:00, 36.83it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████                                                                              | 32/60 [00:00<00:00, 36.96it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 36/60 [00:00<00:00, 36.98it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 40/60 [00:01<00:00, 37.03it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 44/60 [00:01<00:00, 37.07it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 48/60 [00:01<00:00, 36.97it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 52/60 [00:01<00:00, 36.99it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.12it/s]\u001b[A\n",
      " 16%|██████████████████████████▉                                                                                                                                             | 4/25 [01:23<07:20, 20.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31       0.20967742 0.40357143 0.38993711 0.72727273 0.3950104\n",
      " 0.77411765]\n",
      "ACC tensor(0.4835)\n",
      "----- Evaluating ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                | 0/60 [00:00<?, ?it/s]\u001b[A/home/cyhung/home/miniconda3/envs/generation_classification/lib/python3.7/site-packages/torch/nn/modules/activation.py:1138: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:126.)\n",
      "  1 if key_padding_mask is not None else 0 if attn_mask is not None else None)\n",
      "\n",
      "  7%|███████████▏                                                                                                                                                            | 4/60 [00:00<00:01, 34.77it/s]\u001b[A\n",
      " 13%|██████████████████████▍                                                                                                                                                 | 8/60 [00:00<00:01, 35.76it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▍                                                                                                                                     | 12/60 [00:00<00:01, 36.28it/s]\u001b[A\n",
      " 27%|████████████████████████████████████████████▌                                                                                                                          | 16/60 [00:00<00:01, 36.62it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                               | 20/60 [00:00<00:01, 36.69it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 24/60 [00:00<00:00, 36.67it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████████████████████████████████████████████▉                                                                                         | 28/60 [00:00<00:00, 36.68it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████                                                                              | 32/60 [00:00<00:00, 36.71it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 36/60 [00:00<00:00, 36.74it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 40/60 [00:01<00:00, 36.84it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 44/60 [00:01<00:00, 36.95it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 48/60 [00:01<00:00, 36.78it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 52/60 [00:01<00:00, 36.77it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.94it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▌                                                                                                                                      | 5/25 [01:44<06:59, 20.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32894737 0.25728155 0.44       0.37644046 0.72580645 0.3782235\n",
      " 0.70810811]\n",
      "ACC tensor(0.4682)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████████████████▌                                                                                                                                      | 5/25 [01:57<07:48, 23.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3770244/1277411989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Classifier(6)\n",
    "#model = Naive()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = 'cuda:1'\n",
    "loss_fn.to(device)\n",
    "for i in tqdm(range(25)):\n",
    "    model.train()\n",
    "    for inp,label,attn in train_dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inp,label,attn = inp.to(device),label.to(device),attn.to(device)\n",
    "        model = model.to(device)\n",
    "        logits = model(inp,attn)\n",
    "        loss = loss_fn(logits,label)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    evaluate(model,test_dataloader,'cuda:1')\n",
    "    #print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72dec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
